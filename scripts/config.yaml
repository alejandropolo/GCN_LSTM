sigma2: 0.1
epsilon: 0.5
train_rate: 0.8
seq_len: 6
pre_len: 12
dropout: 0.2
gc_layer_sizes:
  - 32
  - 10
gc_activations:
  - "relu"
  - "relu"
lstm_layer_sizes:
  - 200
  - 200
lstm_activations:
  - "tanh"
  - "tanh"
epochs: 1000
batch_size: 60
model_name: "Model_Adam_00005"
optimizer_name: "Adam"
learning_rate: 0.0005
momentum: 0.7
val_split: 0.15