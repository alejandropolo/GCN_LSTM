sigma2: 0.1
epsilon: 0.5
train_rate: 0.8
seq_len: 12
pre_len: 6
dropout: 0.2
gc_layer_sizes:
  - 16
  - 10
gc_activations:
  - "relu"
  - "relu"
lstm_layer_sizes:
  - 200
  - 200
lstm_activations:
  - "relu"
  - "relu"
epochs: 1000
batch_size: 60
model_name: "Model_Adam_00001"
optimizer_name: "Adam"
learning_rate: 0.00001
momentum: 0.8